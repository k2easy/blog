#  PostgreSQL 13 Released!

Posted on **2020-09-24** by PostgreSQL Global Development Group

In PostgreSQL 13, more types of [aggregate](https://www.postgresql.org/docs/13/functions-aggregate.html) and [grouping set](https://www.postgresql.org/docs/13/queries-table-expressions.html#QUERIES-GROUPING-SETS) queries can leverage PostgreSQLâ€™s efficient hash aggregation functionality, as queries with large aggregates do not have to fit entirely into memory. Queries with [partitioned tables](https://www.postgresql.org/docs/13/ddl-partitioning.html) have received a performance boost, as there are now more cases where partitions can be pruned and where partitions can be directly joined.

 [`datetime()`](https://www.postgresql.org/docs/13/functions-json.html#FUNCTIONS-SQLJSON-OP-TABLE) function to its SQL/JSON path support, which converts valid time formats  to PostgreSQL-native types.

[`gen_random_uuid()`](https://www.postgresql.org/docs/13/functions-uuid.html), is now available without having to install any extensions.

PostgreSQLâ€™s partitioning system is more flexible, as partitioned tables fully support logical replication and BEFORE row-level triggers.

#  æ‰‹å†Œ

http://www.postgres.cn/docs/12/index.html

https://www.postgresql.org/docs/13/index.html

è¡Œæ–‡çº¦å®š

> æ–¹æ‹¬å¼§ï¼ˆ`[`å’Œ`]`ï¼‰è¡¨ç¤ºå¯é€‰çš„éƒ¨åˆ†ï¼ˆåœ¨ Tcl å‘½ä»¤é‡Œï¼Œä½¿ç”¨çš„æ˜¯é—®å· ï¼ˆ`?`ï¼‰ï¼Œå°±åƒé€šå¸¸çš„ Tcl ä¸€æ ·ï¼‰ã€‚ 
>
> èŠ±æ‹¬å¼§ï¼ˆ`{`å’Œ`}`ï¼‰å’Œç«–çº¿ï¼ˆ`|`ï¼‰è¡¨ç¤ºä½ å¿…é¡»é€‰å–ä¸€ä¸ªå€™é€‰ã€‚
>
>  ç‚¹ï¼ˆ`...`ï¼‰è¡¨ç¤ºå®ƒå‰é¢çš„å…ƒç´ å¯ä»¥è¢«é‡å¤ã€‚

ä¸€ä¸ªæœåŠ¡å™¨è¿›ç¨‹ï¼Œå®ƒç®¡ç†æ•°æ®åº“æ–‡ä»¶ã€æ¥å—æ¥è‡ªå®¢æˆ·ç«¯åº”ç”¨ä¸æ•°æ®åº“çš„è”æ¥å¹¶ä¸”ä»£è¡¨å®¢æˆ·ç«¯åœ¨æ•°æ®åº“ä¸Šæ‰§è¡Œæ“ä½œã€‚ è¯¥æ•°æ®åº“æœåŠ¡å™¨ç¨‹åºå«åš`postgres`ã€‚       

wiki https://wiki.postgresql.org/wiki/Main_Page

createdb mydb
dropdb mydb

è¿è¡ŒPostgreSQLçš„äº¤äº’å¼ç»ˆç«¯ç¨‹åºï¼Œå®ƒè¢«ç§°ä¸º*psql*ï¼Œ å®ƒå…è®¸ä½ äº¤äº’åœ°è¾“å…¥ã€ç¼–è¾‘å’Œæ‰§è¡ŒSQLå‘½ä»¤ã€‚      

psql --help

```
psql -V ,--version
psql -l ,--list 
```

$ psql -l
psql: error: could not connect to server: could not connect to server: No such file or directory
	Is the server running locally and accepting
	connections on Unix domain socket "/tmp/.s.PGSQL.5432"?

To change the password, simply type `sudo passwd postgres` and set up a new password.

wiki ä¸åˆ©äºå…¥é—¨ï¼Œå…ˆå­¦ä¹  http://postgresguide.com/setup/users.html



# install

brew install postgresql
brew info postgresql

To have launchd start postgresql now and restart at login:
  brew services start postgresql   // restart
Or, if you don't want/need a background service you can just run:
  pg_ctl -D /usr/local/var/postgres start

To migrate existing data from a previous major version of PostgreSQL run:
  brew postgresql-upgrade-database

This formula has created a default database cluster with:
  initdb --locale=C -E UTF-8 /usr/local/var/postgres

brew services --help
brew services list 



psql -h localhost -p 5432



ls /usr/local/bin | grep 'postgre*' // postgres

$ cd /usr/local/Cellar/postgresql

psql æŠ¥é”™è¿æ¥ä¸ä¸Šï¼Œbrew services restart -vvv postgresql æ˜¾ç¤ºå¦‚ä¸‹

```
<array>
       <string>/usr/local/opt/postgresql/bin/postgres</string>
       <string>-D</string>
       <string>/usr/local/var/postgres</string>
     </array>
     <key>RunAtLoad</key>
     <true/>
     <key>WorkingDirectory</key>
     <string>/usr/local</string>
     <key>StandardOutPath</key>
     <string>/usr/local/var/log/postgres.log</string>
```

tial -100f /usr/local/var/log/postgres.log 

database files are incompatible with server
2020-10-23 11:00:18.463 CST [98807] DETAIL:  The data directory was initialized by PostgreSQL version 11, which is not compatible with this version 13.0.

brew info postgresql 

==> Caveats
To migrate existing data from a previous major version of PostgreSQL run:
  brew postgresql-upgrade-database

å¤±è´¥ï¼Œæ— æ³•ä»æŠŠæ•°æ®æ–‡ä»¶ä»11å‡çº§åˆ°13å…«æœ¬

brew doctor 

brew cleanup

å®Œå…¨åˆ é™¤é‡è£…

```
brew uninstall postgresql

# remove all local pgsql file 
rm -rf /usr/local/var/postgres
rm -rf .psql_history .psqlrc .psql.local .pgpass .psqlrc.local

brew list --formula | grep "postgre*"
```



postgrest
Serves a fully RESTful API from any existing PostgreSQL database



brew install postgresql
postges --version //13.0

å®‰è£…è¿‡ç¨‹ä¸­è‡ªåŠ¨åˆ›å»ºé»˜è®¤æ•°æ®åº“å­˜å‚¨ç›®å½• *"/usr/local/var/postgres"* ,è‹¥æ— åˆ™è‡ªåˆ›å»º
initdb /usr/local/var/postgresï¼Œ **create a physical PostgreSQL Database**

$ pg_ctl --help
pg_ctl is a utility to initialize, start, stop, or control a PostgreSQL server.



```jsx
brew services stop postgres
pg_ctl -D /usr/local/var/postgres start
pg_ctl -D /usr/local/var/postgres stop

createdb test ;// CREATE DATABASE test;
psql test ;
select version(); 
exit;
```

navicat é“¾æ¥ localhost 5432 , initial database: postgres ,user:demo ,password: æ— ã€‚



# ç”¨æˆ·

```
create user admin with password 'demo2020';
create database pgguide;
postgres=# grant all privileges on database pgguide to admin; 
        // grant select  
```

å¯¼å…¥exampleæ•°æ®

```
curl -L -O http://cl.ly/173L141n3402/download/example.dump
pg_restore --no-owner --dbname pgguide example.dump 
æç¤º shema public already exists ,ä½†æ˜¯æ•°æ®ä¹ŸæˆåŠŸå€’å…¥è¿›å»äº†
```

```
psql --dbname pgguide
```

```
pgguide=# \d   æ˜¾ç¤ºtableåˆ—è¡¨
\d users æ˜¾ç¤ºusersè¡¨ç»“æ„
```

# view

> "a view consists of a stored query accessible as a virtual table in a  relational database or a set of documents in a document-oriented database composed  of the result set of a query or map and reduce functions."

```
CREATE OR REPLACE VIEW employee_view AS
SELECT  ...
```

# Window functions

> unlike regular aggregate functions, use of a window function does not  cause rows to become grouped into a single output row â€” the rows retain  their separate identities. Behind the scenes, the window function is  able to access more than just the current row of the query result.".
>
> A window function performs a calculation across a set of table rows that are somehow related to the current row.

ç¤ºä¾‹1 è·å–å„ä¸ªéƒ¨é—¨å·¥èµ„æ’åç¬¬ä¸€çš„å‘˜å·¥

```sql
SELECT *
FROM
    (
        SELECT last_name,
               salary,
               department,
               rank() OVER (
                PARTITION BY department
                ORDER BY salary
                DESC
               )
        FROM employees)
    sub_query
WHERE rank = 1;	

å­æŸ¥è¯¢ä½¿ç”¨ rank() çª—å£å‡½æ•° åœ¨ departmentä¸Šåˆ†åŒºæ’åº
```

# Backup and Restore

```
psql -l //æ˜¾ç¤ºæ‰€æœ‰db
template1 template0 ä¸¤ä¸ªåº“æ˜¯æ¨¡ç‰ˆåº“ï¼Œæ˜¯åˆ›å»ºå…¶ä»–åº“çš„æ¨¡ç‰ˆ
```

> `template1` is the one used by default, and you can alter / add objects there to affect every newly created DB. `template0` starts out being the same and should never be changed - to provide a virgin template with original settings.



[pg_dump](http://www.postgresql.org/docs/8.4/static/app-pgdump.html) is the utility for backing up your database.

- Plaintext format (readable and large) vs. binary format (unreadable and small) vs. tarball (ideal for restore)

- All of your database or specific schemas/tables

```
pg_dump database_name_here > database.sql
pg_dump -Fc database_name_here > database.bak # compressed binary format
pg_dump -Ft database_name_here > database.tar # tarball


# database already exists
pg_restore -Fc database.bak # restore compressed binary format
pg_restore -Ft database.tar # restore tarball
# database not exists
pg_restore -Fc -C database.bak # -C create 
```

excelæœ‰æœ€å¤§è¡Œé™åˆ¶ï¼Œcsv is text æ²¡æœ‰æœ€å¤§è¡Œé™åˆ¶ã€‚

# COPY

-   binary
-   tab delimited
-   csv delimited

```
pgguide=# \copy (select * from users where id=1)  TO '~/employ_1.tsv';
... TO '~/employees.csv' WITH (FORMAT CSV);
... TO '~/employees.dat' WITH (FORMAT "Binary")

å¯¼å…¥è¡¨
\copy employees FROM '~/employees.tsv';
\copy employees FROM '~/employees.csv' WITH CSV;
\copy employees FROM '~/employees.dat' WITH BINARY;
```

# Psql CLI

> Psql is the interactive terminal for working with Postgres.

-   -h the host to connect to

-   -U the user to connect with

- -p the port to connect to (default is 5432)

  psql -h localhost -U username databasename

  å¦ä¸€ç§ç™»å½•æ–¹å¼ use a full string and let psql parse it

```
psql "dbname=dbhere host=hosthere user=userhere password=pwhere port=5432 sslmode=require"
```

 Running \? will give you a list of all available commands,

\timing  å¼€å¯æŸ¥è¯¢ç”¨æ—¶

\d+ æ˜¾ç¤ºè¡¨ä¿¡æ¯ ï¼Œ + more info

\du users

\l+   list all db

\dn+ list all schemas

\df+ list all functions

\c dbname    //connect other db

\q   quit

\e   æ‰“å¼€psql.editor. Text editor inside psql,Pretty handy for query modifications.

å¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼

\df *to_array* lists all functions that contain to_array in its name.å‡½æ•°æŸ¥æ‰¾



```
-- Automatically format output based on result length and screen
\x auto
pgguide=# \x
Expanded display is on.

-- Prettier nulls
\pset null '#'

-- Save history based on database name
\set HISTFILE ~/.psql_history- :DBNAME

\dt åªæ˜¾ç¤ºè¡¨ ä¸æ˜¾ç¤ºview 
jsonb_pretty(yourcolumnhere). This will take care of making that huge JSON blob nice and readable.
```





# date time

## Datatypes

-   Date - Date only (2012-04-25)
-   Time - Time only (13:00:00.00)
-   Timestamp - Date and Time (2012-04-25 13:00:00.00)
-   Time with Timezone - Time only (13:00:00.00 PST)
-   Timestamp with Timezone (2012-04-25 13:00:00.00 PST)
-   Interval - A span of time (4 days)

## date_trunc

```sql
 SELECT count(*), date_trunc('day', created_at)
FROM users
GROUP BY 2
ORDER BY 2 DESC;
```

ä½¿ç”¨2è¡¨ç¤ºç¬¬äºŒä¸ªå­—æ®µï¼Œç”Ÿäº§ç¯å¢ƒä¸æ¨èï¼Œä¸´æ—¶(ad-hoc )ä½¿ç”¨ok

 select (now() - interval '1 month');

```sql
WHERE created_at >= (now() - interval '1 month');
//1 day , 1 days ,1 week 

select date_trunc('week',now() - interval '1 day'); -- å–å‡ºçš„æ˜¯è¿™å‘¨çš„å‘¨ä¸€æ—¥æœŸ

-- æ¯å‘¨æ³¨å†Œç”¨æˆ·æ•°
SELECT date_trunc('week', created_at),
       count(*)
FROM users
GROUP BY 1
ORDER BY 1 DESC; 

```

## generate_series

å¦‚æœæŸä¸€å‘¨æ²¡æœ‰æ³¨å†Œç”¨æˆ·ä¼šå‡ºç°æ—¶é—´æ®µæŠ˜çº¿å›¾ä¸è¿ç»­

```sql
with weeks as (
  select week
  from generate_series('2017-01-01'::date, now()::date, '1 week'::interval) week
) -- è¿ç»­æ—¶é—´æ®µ

SELECT weeks.week,
       count(*)
FROM weeks,
     users
WHERE users.created_at > weeks.week
  AND users.created_at <= (weeks.week - '1 week'::interval)
GROUP BY 1
ORDER BY 1 DESC;

```

## timestamps

timestampsã€timestamptzï¼ˆwith timezone embedded inï¼‰æ¨è

## extract 

```sql
 
select date_part('month', timestamp '2001-02-16 20:38:40')

```







# ç£ç›˜å ç”¨

Apart from general OS level disk usage commands like `du -sh` or `df -H`, there might be situations where we might to track database/table/index size individually.

```
\l+ æ˜¾ç¤ºæ‰€æœ‰åº“ç£ç›˜å¤§å°
pgguide=# select pg_size_pretty(pg_database_size('dbname|tableName|index')); 

 total size of a table along with all of the indexes,
 # select pg_size_pretty(pg_total_relation_size('users'));
```

# Index

> An index is a specific structure that organizes a reference to your data that makes it easier to look up.
>
> Indexes are great for accessing your data faster. However, the trade off is that for each index you have you will insert data at a slower pace. Essentially when you insert your data with an index it must write data to two places as well as maintain the sort on the index as you insert data. 
>
> Certain indexes additionally will be more effective than others, such as indexes on numbers or timestamps (text is expensive).

```sql
CREATE INDEX idx_salary ON employees(last_name, salary);
```

### Create Index Concurrently

> å½“åˆ›å»ºç´¢å¼•æ—¶ä¼šé”è¡¨ï¼Œå°è¡¨å¾ˆå¿«ï¼Œå¤§è¡¨ç”Ÿæˆç´¢å¼•æ—¶ä¼šé€ æˆè¯¥è¡¨ä¸€æ®µæ—¶é—´æ— æ³•è®¿é—®ã€‚
>
>  By using CREATE INDEX CONCURRENTLY your index will be built without a long lock on the table while index built. 

```
create index concurrently idx_salary on employee(last_name,salary)
```

An example case is when your query returns a large percentage of the  data that exists in a table, it may not use the index. This is because  it is easiest to scan the table once, versus using the index then making additional lookups.

count(*) queries can be optimized with indexes thanks to index-only scans.* 

### [Covering Indexes](https://wiki.postgresql.org/wiki/Index-only_scans#Covering_indexes)

> Also since Postgres version 9.2, queries that touch only an index can be much faster. For this reason, it can be useful to include important  data with an index. Performance can be particularly improved if the  newly-created index has many fewer columns than the table being indexed, since many fewer pages must be retrieved from the disk in order to  satisfy the query.

# **explain**

Every query within Postgres has an execution plan when executed. There are three forms of running **explain** to expose this to you:

-   The generic form (only shows what is likely to happen)
-   Analyze form (which actually runs the query and outputs what does happen)
-   Verbose form (stay away)

```
EXPLAIN ANALYZE SELECT last_name FROM employees where salary >= 50000;
```

![image](https://cdn.jsdelivr.net/gh/k2easy/picgo/2020/11/0120201101100931.png)

In this case we see there's a high time spent and a sequential scan. As a result we may want to try to add an index and examine the results:

```
CREATE INDEX idx_emps on employees (salary);
```



# navicat

shortcut
cmd+y new query
cmd+r refresh 
cmd+ + add record , - delete record, å›è½¦ ä¿å­˜changes

`Ctrl + /` - To comment a block of code

`Ctrl + Shift + /` - To uncomment a block of code'

navicat ä¸å¤ªå¥½ç”¨ï¼Œå°è¯•ä¸‹ $ brew install pgcli  # Only on macOS

[# pgcli](https://github.com/dbcli/pgcli)

```shell
$ pgcli [database_name]

or

$ pgcli postgresql://[user[:password]@][netloc][:port][/dbname][?extra=value[&other=other-value]]

$ pgcli postgresql://demo@localhost:5432
FATAL:  database "demo" does not exist

$ pgcli postgresql://demo@localhost:5432/postgres
Server: PostgreSQL 13.0

```

`SELECT * FROM <tab>` will only show table names.

`SELECT * FROM users WHERE <tab>` will only show column names.

Primitive support for `psql` back-slash commands.

Pretty prints tabular data.

```
~/.config/pgcli/config
```



[# mycli](https://github.com/dbcli/mycli)

```shell
$ brew update && brew install mycli  # Only on macOS

 mycli mysql://my_user@my_host.com:3306/my_database
```





# Conditional Constraints

> There are times where  you may want data constraints, but only want them to exist in certain cases.

By using a [Partial Indexes](http://www.postgresql.org/docs/9.1/static/indexes-partial.html) this becomes simpler by placing a unique index on only non-deleted users:

```sql
create unique index user_email on users(email) where deleted_at is null;
```

# Cache

80/20 rule with 20% of your data accounting for 80% of the reads 
å®é™…åº”ç”¨ä¸­ç»å¸¸ä½¿ç”¨çš„åªæ˜¯å°‘éƒ¨åˆ†çƒ­ç‚¹æ•°æ®ã€‚

```text
SELECT
       sum(heap_blks_read) as heap_read, 
       sum(heap_blks_hit) as heap_hit, 
       (sum(heap_blks_hit) - sum(heap_blks_read)) / sum(heap_blks_hit) as ratio

FROM
     pg_statio_user_tables;
```

If you find yourself with a ratio significantly lower than 99% then you  likely want to consider increasing the cache available to your database, ...

# HStore

 *With the release of Postgres 9.4 and JSONB,* in most cases JSONB is  a better approach than simply HStore.

HStore is a key value store within Postgres. //hstore,json,jsonb

*For a more in depth comparisson you can check out [this post](https://www.citusdata.com/blog/2016/07/14/choosing-nosql-hstore-json-jsonb/) by [Citus Data](https://www.citusdata.com)*

> JSONB is a binary representation of JSON, this means itâ€™s compressed  and more efficient for storage than just text. 
>
> Creating a GIN index on a JSONB column will create an index on every key and value within that JSON document.

# JSONB

é€‚ç”¨åœºæ™¯ï¼š

- Event tracking data, where you may want to include the payload in the event which might varyã€‚ç§»åŠ¨å˜æ¢æ•°æ®å¦‚ï¼šå®šä½æ•°æ®
- Gaming data is especially common, especially where you have single player  games and have a changing schema based on the state of the user // æ¸¸æˆäººç‰©è£…å¤‡ç­‰çº§ç­‰
- Tools that integrate multiple data sources, an example here may be a tool  that integrates customers databases to Salesforce to Zendesk to  something else. The mix of schemas makes doing this in a multitenant  fashion more painful than it has to be.//æ··åˆç¬¬ä¸‰æ–¹å®šä¹‰çš„æ•°æ®

```sql
CREATE TABLE integrations (id UUID, data JSONB);
INSERT INTO integrations VALUES (
  gen_random_uuid(),
  '{
     "service": "salesforce",
     "id": "AC347D212341XR",
     "email": "craig@citusdata.com",
     "occurred_at": "8/14/16 11:00:00",
     "added": {
       "lead_score": 50
     },
     "updated": {
       "updated_at": "8/14/16 11:00:00"
     }
   }');
select data->'email' as email   from integrations where id=?

-- Extracting an attribute as textï¼Œ -- text æ²¡æœ‰å¼•å·åŒ…å›´
pgguide=# select data->'email' as mail  from integrations limit 1;
-[ RECORD 1 ]---------------
mail | "craig@citusdata.com"

pgguide=# select data->>'email' as mail  from integrations limit 1;
-[ RECORD 1 ]-------------
mail | craig@citusdata.com



 select *
  from integrations
	where data->'email' ? 'craig@citusdata.com'; // ? =

jsonbç´¢å¼•
CREATE INDEX idx_products_attributes ON products USING GIN (attributes);

-- pretty jsonb 
-- å‘½ä»¤è¡Œæ¯”navicatå¥½ç”¨
pgguide=# select jsonb_pretty(data) from integrations;
-[ RECORD 1 ]+-----------------------------------------
jsonb_pretty | {                                       +
             |     "id": "AC347D212341XR",             +
             |     "added": {                          +
             |         "lead_score": 50                +
             |     },                                  +
             |     "email": "craig@citusdata.com",     +
             |     "service": "salesforce",            +
             |     "updated": {                        +
             |         "updated_at": "8/14/16 11:00:00"+
             |     },                                  +
             |     "occurred_at": "8/14/16 11:00:00"   +
             | }
             
```

```sql
select jsonb_object_keys(data) from test;


```

## jsonb_to_record

```sql
select *
from (
 values(1,2),(3,4)
) t1;

WITH t(v) AS ( VALUES
  ('{
     "a":1,
     "b":[1,2,3],
     "c":"bar",
     "d":{
        "key1":"value1",
        "key2":"value2"
     }
   }'::JSONB)
)
select * from t ;
-- :: å€¼ç±»å‹

SELECT x1.*,x2.* FROM t,
    jsonb_to_record(v) as x1(a int,b text,c text,d jsonb),
    jsonb_to_record(v->'d') as x2(key1 text,key2 text);

 a |     b     |  c  |                  d                   |  key1  |  key2  
---+-----------+-----+--------------------------------------+--------+--------
 1 | [1, 2, 3] | bar | {"key1": "value1", "key2": "value2"} | value1 | value2
(1 row)


ç­‰åŒäº 
SELECT id, (data->>'a')::int AS a, (data->>'b')::int AS b
         , (data->>'c')::int AS c, (data->>'d')::int AS d
FROM   test;
```

 



# TEMP TABLE

```sql
CREATE TEMP TABLE obj(a int, b int, c int, d int);
```







# create table

```sql
drop table if exists test;
create table test(
 id serial PRIMARY key,
 name varchar
);
comment on table test is 'æµ‹è¯•';
comment on table test.id is 'è‡ªå¢åºåˆ—å·,1~';

```



# Arrays

> The type of the array can be an inbuilt type, a user-defined type or an enumerated type.

```sql
create TABLE test_array(
 id serial primary key,
 name text,
 members text[]
);

insert into test_array(name,members) values('å°æ˜',ARRAY['å°æ˜1','å°æ˜2'])
update  test_array set members[1]='test' where id =1
select members[1:2] from test_array;

-- æœç´¢
select name from test_array where 'Mason' = ANY(members);
```

# Enumerated Data Types

```sql
-- æ²¡æœ‰enumç±»å‹ï¼Œæœ‰è‡ªå®šä¹‰enum
create type e_contact_method as ENUM(
 'email',
 'sms',
 'phone'
);
alter type e_contact_method add value 'facebook' after 'sms'; -- before 

select t.typname, e.enumlabel, e.enumsortorder
from pg_type t, pg_enum e 
where t.oid = e.enumtypid 
order by e.enumsortorder;

 create TABLE test_enum(
 id serial primary key,
 name e_contact_method
);

insert into test_enum(name) values('email'); -- '1' invalid input 
```

 Postgres does not provide a way to remove values from enums.

> Although `enum` types are primarily intended for static sets  of values, there is support for adding new values to an existing enum  type, and for renaming values (see `ALTER TYPE`). Existing values cannot be removed from an enum type.
>
> create a new type without the value, convert all existing uses of the old type to use the new type, then drop the old type.

```sql
ALTER TYPE admin_level1 ADD VALUE 'god';
DELETE FROM blah WHERE power = 'god'; -- or update

-- Convert to new type, casting via text representation
ALTER TABLE blah 
  ALTER COLUMN power TYPE admin_level1_new 
    USING (power::text::admin_level1_new);

-- and swap the types
DROP TYPE admin_level1;

ALTER TYPE admin_level1_new RENAME TO admin_level1;
```

# CTEs

Long complex SQL queries aren't always the most readable thing. 
cte ,common table expressions 

å¯¹æ¯”view

ç±»ä¼¼subquery 
Views can be indexed but CTE can't.

Views being a physical object on database (but does not store data  physically) and can be used on multiple queries, thus provide  flexibility and centralized approach. CTE, on the other hand are  temporary and will be created when they are used; that's why they are  called as `inline view`.

cteä¸é€‚åˆå¤§æ•°æ®é‡çš„å¤„ç†ï¼Œ   Dealing with 3.5 million rows in CTE will create extra overhead on  TempDb which will eventually slow down SQL Server performance. Remember, CTE is a disposable view hence no statistics are stored and you can't  create Indexes too. It is just like a sub query. 

ä¼˜ç‚¹ï¼šä½¿å¤æ‚çš„sqlç®€æ´åŒ–

```sql
WITH user_task AS 
(
    SELECT 
        u.id AS user_id,
        p.id AS project_id,
        u.email,
        array_agg(t.name) AS task_list,
        p.title
    FROM
        project p,
        task t,
        user_ u
    WHERE
            u.id = t.user_id
        AND p.id = t.project_id
    GROUP BY
        u.id,
        p.id
),

--- Calculates the total task per each project
total_task_per_project AS 
(
    SELECT 
        t.project_id,
        count(*) as task_count
    FROM 
        task t
    GROUP BY 
        t.project_id
),

--- Calculates the projects per each user
task_per_project_per_user AS 
(
    SELECT 
        t.user_id,
        t.project_id,
        count(*) as task_count
    FROM 
        task t
    GROUP BY 
        t.user_id, 
        t.project_id
),

--- Gets user ids that have over 50% of task assigned
overloaded_user AS 
(
    SELECT 
        tpu.user_id,
        tpu.project_id
    FROM 
        task_per_project_per_user tpu,
        total_task_per_project pp
    WHERE
            tpu.project_id = pp.project_id
        AND tpu.task_count > (pp.task_count / 2)
)

SELECT 
    ut.email,
    ut.task_list,
    ut.title
FROM 
     user_task ut,
     overloaded_user ou
WHERE
         ut.user_id = ou.user_id
     AND ut.project_id = ou.project_id
;
```

 

# cn/docs

www.postgres.cn/docs/12/tutorial-start.html

```shell
createdb mydb
dropdb mydb
psql mydb
\q é€€å‡º
```

SQL æ˜¯å¯¹å…³é”®å­—å’Œæ ‡è¯†ç¬¦å¤§å°å†™ä¸æ•æ„Ÿçš„è¯­è¨€ï¼Œåªæœ‰åœ¨æ ‡è¯†ç¬¦ç”¨åŒå¼•å·åŒ…å›´æ—¶æ‰èƒ½ä¿ç•™å®ƒä»¬çš„å¤§å°å†™ã€‚

**SQLç±»å‹**

```
int`ã€`smallint`ã€`real`ã€`double precision`ã€`char(*`N`*)`ã€`varchar(*`N`*)`ã€`date`ã€`time`ã€`timestamp`å’Œ`interval
varchar(80)
point 
```

PostgreSQLä¸­å¯ä»¥å®šåˆ¶ä»»æ„æ•°é‡çš„ç”¨æˆ·å®šä¹‰æ•°æ®ç±»å‹ã€‚å› è€Œç±»å‹åå¹¶ä¸æ˜¯è¯­æ³•å…³é”®å­— 

```
create table weather(
	city varchar(80) ,
	temp_lo int,
	temp_hi int,
	prcp real ,-- æ¹¿åº¦ 
	date date,-- '2020-10-20'  dateç±»å‹å®é™…ä¸Šå¯¹å¯æ¥æ”¶çš„æ ¼å¼ç›¸å½“çµæ´»,æ¨èå¦‚æ­¤
)     
drop table tablename;

CREATE TABLE cities (
    name            varchar(80),
    location        point  -- '(-194.0,53.0)'
);
```

`COPY`ä»æ–‡æœ¬æ–‡ä»¶ä¸­è£…è½½å¤§é‡æ•°æ®ã€‚è¿™ç§æ–¹å¼é€šå¸¸æ›´å¿«ï¼Œå› ä¸º`COPY`å‘½ä»¤å°±æ˜¯ä¸ºè¿™ç±»åº”ç”¨ä¼˜åŒ–çš„ï¼Œ åªæ˜¯æ¯” `INSERT`å°‘ä¸€äº›çµæ´»æ€§

```
COPY weather FROM '/home/user/weather.txt';
```

è¿™é‡Œæºæ–‡ä»¶çš„æ–‡ä»¶åå¿…é¡»åœ¨è¿è¡Œåç«¯è¿›ç¨‹çš„æœºå™¨ä¸Šæ˜¯å¯ç”¨çš„ï¼Œ è€Œä¸æ˜¯åœ¨å®¢æˆ·ç«¯ä¸Šï¼Œå› ä¸ºåç«¯è¿›ç¨‹å°†ç›´æ¥è¯»å–è¯¥æ–‡ä»¶ã€‚ 

äººä»¬å¹¿æ³›è®¤ä¸ºåœ¨ä¸€ä¸ªè¿æ¥æŸ¥è¯¢ä¸­é™å®šæ‰€æœ‰åˆ—åæ˜¯ä¸€ç§å¥½çš„é£æ ¼ï¼Œè¿™æ ·å³ä½¿æœªæ¥å‘å…¶ä¸­ä¸€ä¸ªè¡¨é‡Œæ·»åŠ é‡ååˆ—ä¹Ÿä¸ä¼šå¯¼è‡´æŸ¥è¯¢å¤±è´¥ã€‚   select t.name,b.name

```sql
SELECT *
    FROM weather, cities
    WHERE city = name;
ç­‰åŒäº
SELECT *
    FROM weather INNER JOIN cities ON (weather.city = cities.name);
```

æ‰«æ`weather`è¡¨ï¼Œ å¹¶ä¸”å¯¹æ¯ä¸€è¡Œéƒ½æ‰¾å‡ºåŒ¹é…çš„`cities`è¡¨è¡Œã€‚å¦‚æœæˆ‘ä»¬æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è¡Œï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€äº›â€œç©ºå€¼â€ä»£æ›¿citiesè¡¨çš„åˆ—ã€‚ è¿™ç§ç±»å‹çš„æŸ¥è¯¢å«*å¤–è¿æ¥* 

```sql
SELECT *
    FROM weather LEFT OUTER JOIN cities ON (weather.city = cities.name);
```

ä¹Ÿå¯ä»¥æŠŠä¸€ä¸ªè¡¨å’Œè‡ªå·±è¿æ¥èµ·æ¥ã€‚è¿™å«åš*è‡ªè¿æ¥*ã€‚  

### èšé›†å‡½æ•°

èšé›†`max`ä¸èƒ½è¢«ç”¨äº`WHERE`å­å¥ä¸­ï¼ˆå­˜åœ¨è¿™ä¸ªé™åˆ¶æ˜¯å› ä¸º`WHERE`å­å¥å†³å®šå“ªäº›è¡Œå¯ä»¥è¢«èšé›†è®¡ç®—åŒ…æ‹¬ï¼›å› æ­¤æ˜¾ç„¶å®ƒå¿…éœ€åœ¨èšé›†å‡½æ•°ä¹‹å‰è¢«è®¡ç®—
æ¯ä¸ªèšé›†ç»“æœéƒ½æ˜¯åœ¨åŒ¹é…è¯¥åŸå¸‚çš„è¡¨è¡Œä¸Šé¢è®¡ç®—çš„ã€‚æˆ‘ä»¬å¯ä»¥ç”¨`HAVING` è¿‡æ»¤è¿™äº›è¢«åˆ†ç»„çš„è¡Œ

```sql
SELECT city, max(temp_lo)
    FROM weather
    GROUP BY city
    HAVING max(temp_lo) < 40;
```

`WHERE`åœ¨åˆ†ç»„å’Œèšé›†è®¡ç®—ä¹‹å‰é€‰å–è¾“å…¥è¡Œï¼ˆå› æ­¤ï¼Œå®ƒæ§åˆ¶å“ªäº›è¡Œè¿›å…¥èšé›†è®¡ç®—ï¼‰ï¼Œ è€Œ`HAVING`åœ¨åˆ†ç»„å’Œèšé›†ä¹‹åé€‰å–åˆ†ç»„è¡Œã€‚

å› æ­¤ï¼Œ`WHERE`å­å¥ä¸èƒ½åŒ…å«èšé›†å‡½æ•°ï¼›  HAVING`å­å¥æ€»æ˜¯åŒ…å«èšé›†å‡½æ•°ï¼ˆä¸¥æ ¼è¯´æ¥ï¼Œä½ å¯ä»¥å†™ä¸ä½¿ç”¨èšé›†çš„`HAVING`å­å¥ï¼Œ ä½†è¿™æ ·åšå¾ˆå°‘æœ‰ç”¨ã€‚åŒæ ·çš„æ¡ä»¶ç”¨åœ¨`WHERE`é˜¶æ®µä¼šæ›´æœ‰æ•ˆï¼‰ã€‚   

```
DELETE FROM tablename; å°†ä»æŒ‡å®šè¡¨ä¸­åˆ é™¤æ‰€æœ‰è¡Œï¼ŒæŠŠå®ƒæ¸…ç©ºã€‚åšè¿™äº›ä¹‹å‰ç³»ç»Ÿä¸ä¼šè¯·æ±‚ä½ ç¡®è®¤ï¼ 
```

### è§†å›¾

```
CREATE VIEW myview AS
    SELECT
```

â€‹    å¯¹è§†å›¾çš„ä½¿ç”¨æ˜¯æˆå°±ä¸€ä¸ªå¥½çš„SQLæ•°æ®åº“è®¾è®¡çš„å…³é”®æ–¹é¢ã€‚è§†å›¾å…è®¸ç”¨æˆ·é€šè¿‡å§‹ç»ˆå¦‚ä¸€çš„æ¥å£å°è£…è¡¨çš„ç»“æ„ç»†èŠ‚ï¼Œè¿™æ ·å¯ä»¥é¿å…è¡¨ç»“æ„éšç€åº”ç”¨çš„è¿›åŒ–è€Œæ”¹å˜ã€‚   

â€‹    è§†å›¾å‡ ä¹å¯ä»¥ç”¨åœ¨ä»»ä½•å¯ä»¥ä½¿ç”¨è¡¨çš„åœ°æ–¹ã€‚åœ¨å…¶ä»–è§†å›¾åŸºç¡€ä¸Šåˆ›å»ºè§†å›¾ä¹Ÿå¹¶ä¸å°‘è§ã€‚   

### å¤–å»º

æˆ‘ä»¬å¸Œæœ›ç¡®ä¿åœ¨`cities`è¡¨ä¸­æœ‰ç›¸åº”é¡¹ä¹‹å‰ä»»ä½•äººéƒ½ä¸èƒ½åœ¨`weather`è¡¨ä¸­æ’å…¥è¡Œã€‚è¿™å«åšç»´æŒæ•°æ®çš„*å¼•ç”¨å®Œæ•´æ€§*ã€‚æ­£ç¡®ä½¿ç”¨å¤–é”®æ— ç–‘ä¼šæé«˜æ•°æ®åº“åº”ç”¨çš„è´¨é‡ï¼Œ

```
CREATE TABLE weather (
        city      varchar(80) references cities(city),
```

### äº‹åŠ¡

äº‹åŠ¡æœ€é‡è¦çš„ä¸€ç‚¹æ˜¯å®ƒå°†å¤šä¸ªæ­¥éª¤æ†ç»‘æˆäº†ä¸€ä¸ªå•ä¸€çš„ã€è¦ä¹ˆå…¨å®Œæˆè¦ä¹ˆå…¨ä¸å®Œæˆçš„æ“ä½œã€‚æ­¥éª¤ä¹‹é—´çš„ä¸­é—´çŠ¶æ€å¯¹äºå…¶ä»–å¹¶å‘äº‹åŠ¡æ˜¯ä¸å¯è§çš„ï¼Œå¹¶ä¸”å¦‚æœæœ‰æŸäº›é”™è¯¯å‘ç”Ÿå¯¼è‡´äº‹åŠ¡ä¸èƒ½å®Œæˆï¼Œåˆ™å…¶ä¸­ä»»ä½•ä¸€ä¸ªæ­¥éª¤éƒ½ä¸ä¼šå¯¹æ•°æ®åº“é€ æˆå½±å“ã€‚   

åŸå­æ›´æ–°ï¼šå½“å¤šä¸ªäº‹åŠ¡å¹¶å‘è¿è¡Œæ—¶ï¼Œæ¯ä¸€ä¸ªéƒ½ä¸èƒ½çœ‹åˆ°å…¶ä»–äº‹åŠ¡æœªå®Œæˆçš„ä¿®æ”¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªäº‹åŠ¡æ­£å¿™ç€æ€»è®¡æ‰€æœ‰æ”¯è¡Œçš„ä½™é¢ï¼Œå®ƒä¸ä¼šåªåŒ…æ‹¬Aliceçš„æ”¯è¡Œçš„æ‰£æ¬¾è€Œä¸åŒ…æ‹¬Bobçš„æ”¯è¡Œçš„å­˜æ¬¾ï¼Œæˆ–è€…åä¹‹ã€‚æ‰€ä»¥äº‹åŠ¡çš„å…¨åšæˆ–å…¨ä¸åšå¹¶ä¸åªä½“ç°åœ¨å®ƒä»¬å¯¹æ•°æ®åº“çš„æŒä¹…å½±å“ï¼Œä¹Ÿä½“ç°åœ¨å®ƒä»¬å‘ç”Ÿæ—¶çš„å¯è§æ€§ã€‚**ä¸€ä¸ªäº‹åŠ¡æ‰€åšçš„æ›´æ–°åœ¨å®ƒå®Œæˆä¹‹å‰å¯¹äºå…¶ä»–äº‹åŠ¡æ˜¯ä¸å¯è§çš„ï¼Œè€Œä¹‹åæ‰€æœ‰çš„æ›´æ–°å°†åŒæ—¶å˜å¾—å¯è§ã€‚**   

å¼€å¯ä¸€ä¸ªäº‹åŠ¡éœ€è¦å°†SQLå‘½ä»¤ç”¨`BEGIN`å’Œ`COMMIT`å‘½ä»¤åŒ…å›´èµ·æ¥ã€‚

```
BEGIN;
UPDATE accounts SET balance = balance - 100.00
    WHERE name = 'Alice';
-- etc etc
COMMIT; -- ROLLBACK
```

PostgreSQLå®é™…ä¸Šå°†æ¯ä¸€ä¸ªSQLè¯­å¥éƒ½ä½œä¸ºä¸€ä¸ªäº‹åŠ¡æ¥æ‰§è¡Œã€‚å¦‚æœæˆ‘ä»¬æ²¡æœ‰å‘å‡º`BEGIN`å‘½ä»¤ï¼Œåˆ™æ¯ä¸ªç‹¬ç«‹çš„è¯­å¥éƒ½ä¼šè¢«åŠ ä¸Šä¸€ä¸ªéšå¼çš„`BEGIN`ä»¥åŠï¼ˆå¦‚æœæˆåŠŸï¼‰`COMMIT`æ¥åŒ…å›´å®ƒã€‚ä¸€ç»„è¢«`BEGIN`å’Œ`COMMIT`åŒ…å›´çš„è¯­å¥ä¹Ÿè¢«ç§°ä¸ºä¸€ä¸ª*äº‹åŠ¡å—*ã€‚   

æŸäº›å®¢æˆ·ç«¯åº“ä¼šè‡ªåŠ¨å‘å‡º`BEGIN`å’Œ`COMMIT`å‘½ä»¤ï¼Œå› æ­¤æˆ‘ä»¬å¯èƒ½ä¼šåœ¨ä¸è¢«å‘ŠçŸ¥çš„æƒ…å†µä¸‹å¾—åˆ°äº‹åŠ¡å—çš„æ•ˆæœã€‚

**ä¿å­˜ç‚¹**

â€‹    å¯ä»¥åˆ©ç”¨*ä¿å­˜ç‚¹*æ¥ä»¥æ›´ç»†çš„ç²’åº¦æ¥æ§åˆ¶ä¸€ä¸ªäº‹åŠ¡ä¸­çš„è¯­å¥ã€‚ä¿å­˜ç‚¹å…è®¸æˆ‘ä»¬æœ‰é€‰æ‹©æ€§åœ°æ”¾å¼ƒäº‹åŠ¡çš„ä¸€éƒ¨åˆ†è€Œæäº¤å‰©ä¸‹çš„éƒ¨åˆ†ã€‚åœ¨ä½¿ç”¨`SAVEPOINT`å®šä¹‰ä¸€ä¸ªä¿å­˜ç‚¹åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¿…è¦æ—¶åˆ©ç”¨`ROLLBACK TO`å›æ»šåˆ°è¯¥ä¿å­˜ç‚¹ã€‚è¯¥äº‹åŠ¡ä¸­ä½äºä¿å­˜ç‚¹å’Œå›æ»šç‚¹ä¹‹é—´çš„æ•°æ®åº“ä¿®æ”¹éƒ½ä¼šè¢«æ”¾å¼ƒï¼Œä½†æ˜¯æ—©äºè¯¥ä¿å­˜ç‚¹çš„ä¿®æ”¹åˆ™ä¼šè¢«ä¿å­˜ã€‚   

ä¸ç®¡æ˜¯é‡Šæ”¾ä¿å­˜ç‚¹è¿˜æ˜¯å›æ»šåˆ°ä¿å­˜ç‚¹éƒ½ä¼šé‡Šæ”¾å®šä¹‰åœ¨è¯¥ä¿å­˜ç‚¹ä¹‹åçš„æ‰€æœ‰å…¶ä»–ä¿å­˜ç‚¹ã€‚   

å½“æäº¤æ•´ä¸ªäº‹åŠ¡å—æ—¶ï¼Œè¢«æäº¤çš„åŠ¨ä½œå°†ä½œä¸ºä¸€ä¸ªå•å…ƒå˜å¾—å¯¹å…¶ä»–ä¼šè¯å¯è§ï¼Œè€Œè¢«å›æ»šçš„åŠ¨ä½œåˆ™æ°¸è¿œä¸ä¼šå˜å¾—å¯è§ã€‚   

`ROLLBACK TO`æ˜¯å”¯ä¸€çš„é€”å¾„æ¥é‡æ–°æ§åˆ¶ä¸€ä¸ªç”±äºé”™è¯¯è¢«ç³»ç»Ÿç½®ä¸ºä¸­æ–­çŠ¶æ€çš„äº‹åŠ¡å—ï¼Œ

```sql
BEGIN;
UPDATE accounts SET balance = balance - 100.00
    WHERE name = 'Alice';
SAVEPOINT my_savepoint;
UPDATE accounts SET balance = balance + 100.00
    WHERE name = 'Bob';
-- oops ... forget that and use Wally's account
ROLLBACK TO my_savepoint;
UPDATE accounts SET balance = balance + 100.00
    WHERE name = 'Wally';
COMMIT;
```

### çª—å£å‡½æ•°

â€‹    ä¸€ä¸ª*çª—å£å‡½æ•°*åœ¨ä¸€ç³»åˆ—ä¸å½“å‰è¡Œæœ‰æŸç§å…³è”çš„è¡¨è¡Œä¸Šæ‰§è¡Œä¸€ç§è®¡ç®—ã€‚è¿™ä¸ä¸€ä¸ªèšé›†å‡½æ•°æ‰€å®Œæˆçš„è®¡ç®—æœ‰å¯æ¯”ä¹‹å¤„ã€‚**ä½†æ˜¯çª—å£å‡½æ•°å¹¶ä¸ä¼šä½¿å¤šè¡Œè¢«èšé›†æˆä¸€ä¸ªå•ç‹¬çš„è¾“å‡ºè¡Œï¼Œ**è¿™ä¸é€šå¸¸çš„éçª—å£èšé›†å‡½æ•°ä¸åŒã€‚å–è€Œä»£ä¹‹ï¼Œè¡Œä¿ç•™å®ƒä»¬ç‹¬ç«‹çš„æ ‡è¯†ã€‚åœ¨è¿™äº›ç°è±¡èƒŒåï¼Œçª—**å£å‡½æ•°å¯ä»¥è®¿é—®çš„ä¸ä»…ä»…æ˜¯æŸ¥è¯¢ç»“æœçš„å½“å‰è¡Œã€‚**   

```sql
SELECT depname, empno, salary, avg(salary) OVER (PARTITION BY depname) FROM empsalary;
```

ç¬¬å››åˆ—è¡¨ç¤ºå¯¹ä¸å½“å‰è¡Œå…·æœ‰**ç›¸åŒ**`depname`å€¼çš„æ‰€æœ‰è¡¨è¡Œå–å¾—å¹³å‡å€¼ï¼ˆè¿™å®é™…å’Œéçª—å£`avg`èšé›†å‡½æ•°æ˜¯ç›¸åŒçš„å‡½æ•°ï¼Œä½†æ˜¯`OVER`å­å¥ä½¿å¾—å®ƒè¢«å½“åšä¸€ä¸ªçª—å£å‡½æ•°å¤„ç†å¹¶åœ¨ä¸€ä¸ªåˆé€‚çš„çª—å£å¸§ä¸Šè®¡ç®—ã€‚ï¼‰ã€‚   

å¯ä»¥é€šè¿‡`OVER`ä¸Šçš„`ORDER BY`æ§åˆ¶çª—å£å‡½æ•°å¤„ç†è¡Œçš„é¡ºåºï¼ˆçª—å£çš„`ORDER BY`å¹¶ä¸ä¸€å®šè¦ç¬¦åˆè¡Œè¾“å‡ºçš„é¡ºåº

```sql
SELECT depname, empno, salary,
       rank() OVER (PARTITION BY depname ORDER BY salary DESC) FROM empsalary;
```

```
  depname  | empno | salary | rank
-----------+-------+--------+------
 develop   |     8 |   6000 |    1
 develop   |    10 |   5200 |    2
 develop   |    11 |   5200 |    2
 develop   |     9 |   4500 |    4
 develop   |     7 |   4200 |    5
 personnel |     2 |   3900 |    1
 personnel |     5 |   3500 |    2
 sales     |     1 |   5000 |    1
 sales     |     4 |   4800 |    2
 sales     |     3 |   4800 |    2
(10 rows)
```

ä¸€ä¸ªçª—å£å‡½æ•°è°ƒç”¨æ€»æ˜¯åŒ…å«ä¸€ä¸ªç›´æ¥è·Ÿåœ¨çª—å£å‡½æ•°ååŠå…¶å‚æ•°ä¹‹åçš„`OVER`å­å¥ã€‚è¿™ä½¿å¾—å®ƒä»å¥æ³•ä¸Šå’Œä¸€ä¸ªæ™®é€šå‡½æ•°æˆ–éçª—å£å‡½æ•°åŒºåˆ†å¼€æ¥ã€‚`OVER`å­å¥å†³å®šç©¶ç«ŸæŸ¥è¯¢ä¸­çš„å“ªäº›è¡Œè¢«åˆ†ç¦»å‡ºæ¥ç”±çª—å£å‡½æ•°å¤„ç†ã€‚`OVER`å­å¥ä¸­çš„`PARTITION BY`å­å¥æŒ‡å®šäº†å°†å…·æœ‰ç›¸åŒ`PARTITION BY`è¡¨è¾¾å¼å€¼çš„è¡Œåˆ†åˆ°ç»„æˆ–è€…åˆ†åŒºã€‚å¯¹äºæ¯ä¸€è¡Œï¼Œçª—å£å‡½æ•°éƒ½ä¼šåœ¨å½“å‰è¡ŒåŒä¸€åˆ†åŒºçš„è¡Œä¸Šè¿›è¡Œè®¡ç®—ã€‚   

ä¸€ä¸ªçª—å£å‡½æ•°æ‰€è€ƒè™‘çš„è¡Œå±äºé‚£äº›é€šè¿‡æŸ¥è¯¢çš„`FROM`å­å¥äº§ç”Ÿå¹¶é€šè¿‡`WHERE`ã€`GROUP BY`ã€`HAVING`è¿‡æ»¤çš„â€œè™šæ‹Ÿè¡¨â€ã€‚
åœ¨ä¸€ä¸ªæŸ¥è¯¢ä¸­å¯ä»¥åŒ…å«å¤šä¸ªçª—å£å‡½æ•°ï¼Œæ¯ä¸ªçª—å£å‡½æ•°éƒ½å¯ä»¥ç”¨ä¸åŒçš„`OVER`å­å¥æ¥æŒ‰ä¸åŒæ–¹å¼åˆ’åˆ†æ•°æ®ï¼Œä½†æ˜¯å®ƒä»¬éƒ½ä½œç”¨åœ¨ç”±è™šæ‹Ÿè¡¨å®šä¹‰çš„åŒä¸€ä¸ªè¡Œé›†ä¸Šã€‚   

å¦‚æœè¡Œçš„é¡ºåºä¸é‡è¦æ—¶`ORDER BY`å¯ä»¥å¿½ç•¥ã€‚`PARTITION BY`åŒæ ·ä¹Ÿå¯ä»¥è¢«å¿½ç•¥ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ä¼šäº§ç”Ÿä¸€ä¸ªåŒ…å«æ‰€æœ‰è¡Œçš„åˆ†åŒºã€‚   

```
SELECT salary, sum(salary) OVER () FROM empsalary;

 salary |  sum
--------+-------
   5200 | 47100
   5000 | 47100
   3500 | 47100
   4800 | 47100
   3900 | 47100
   4200 | 47100
```

**`OVER`å­å¥ä¸­æ²¡æœ‰`ORDER BY`ï¼Œçª—å£å¸§å’Œåˆ†åŒºä¸€**æ ·
**ç¼ºå°‘`PARTITION BY`åˆ™å’Œæ•´ä¸ªè¡¨ä¸€æ ·**

å¯¹äºæ¯ä¸€è¡Œï¼Œåœ¨å®ƒçš„åˆ†åŒºä¸­çš„è¡Œé›†è¢«ç§°ä¸ºå®ƒçš„çª—å£å¸§ã€‚ ä¸€äº›çª—å£å‡½æ•°åªä½œç”¨åœ¨*çª—å£å¸§*ä¸­çš„è¡Œä¸Šï¼Œè€Œä¸æ˜¯æ•´ä¸ªåˆ†åŒºã€‚// åœ¨åˆ†åŒºä¸­çš„å½“å‰èŒƒå›´å†…çš„è¡Œé›†åˆå°±æ˜¯çª—å£å¸§

é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœä½¿ç”¨`ORDER BY`ï¼Œåˆ™å¸§åŒ…æ‹¬**ä»åˆ†åŒºå¼€å§‹åˆ°å½“å‰è¡Œçš„æ‰€æœ‰è¡Œ**ï¼Œ**ä»¥åŠåç»­ä»»ä½•ä¸å½“å‰è¡Œåœ¨`ORDER BY`å­å¥ä¸Šç›¸ç­‰çš„è¡Œ**ã€‚å¦‚æœ`ORDER BY`è¢«å¿½ç•¥ï¼Œåˆ™é»˜è®¤å¸§åŒ…å«æ•´ä¸ªåˆ†åŒºä¸­æ‰€æœ‰çš„è¡Œã€‚

```
SELECT salary, sum(salary) OVER (ORDER BY salary) FROM empsalary;
 salary |  sum
--------+-------
   3500 |  3500
   3900 |  7400
   4200 | 11600
   4500 | 16100
   4800 | 25700
   4800 | 25700
   5000 | 30700  
   5200 | 41100 //order by salary,salaryç›¸åŒåˆ™å½“å‰è¡Œå»¶ä¼¸ï¼Œåˆ™å±äºåŒä¸€ä¸ªçª—å£å¸§
   5200 | 41100
   6000 | 47100
(10 rows)
è¿™é‡Œçš„åˆè®¡æ˜¯ä»ç¬¬ä¸€ä¸ªï¼ˆæœ€ä½çš„ï¼‰è–ªæ°´ä¸€ç›´åˆ°å½“å‰è¡Œï¼ŒåŒ…æ‹¬ä»»ä½•ä¸å½“å‰è¡Œç›¸åŒçš„è¡Œï¼ˆæ³¨æ„ç›¸åŒè–ªæ°´è¡Œçš„ç»“æœï¼‰ã€‚ 
```

çª—å£å‡½æ•°åªå…è®¸å‡ºç°åœ¨æŸ¥è¯¢çš„`SELECT`åˆ—è¡¨å’Œ`ORDER BY`å­å¥ä¸­ã€‚å®ƒä»¬ä¸å…è®¸å‡ºç°åœ¨å…¶ä»–åœ°æ–¹ï¼Œä¾‹å¦‚`GROUP BY`ã€`HAVING`å’Œ`WHERE`å­å¥ä¸­ã€‚**è¿™æ˜¯å› ä¸ºçª—å£å‡½æ•°çš„æ‰§è¡Œé€»è¾‘æ˜¯åœ¨å¤„ç†å®Œè¿™äº›å­å¥ä¹‹åã€‚**å¦å¤–ï¼Œ**çª—å£å‡½æ•°åœ¨éçª—å£èšé›†å‡½æ•°ä¹‹åæ‰§è¡Œã€‚**è¿™æ„å‘³ç€å¯ä»¥åœ¨çª—å£å‡½æ•°çš„å‚æ•°ä¸­åŒ…æ‹¬ä¸€ä¸ªèšé›†å‡½æ•°ï¼Œä½†åè¿‡æ¥ä¸è¡Œã€‚   

å¦‚æœéœ€è¦åœ¨çª—å£è®¡ç®—æ‰§è¡Œåè¿›è¡Œè¿‡æ»¤æˆ–è€…åˆ†ç»„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å­æŸ¥è¯¢

```sql
SELECT  *
FROM
  (SELECT  rank() OVER (PARTITION BY depname ORDER BY salary DESC, empno) AS pos
     FROM empsalary
  ) AS ss
WHERE pos < 3;
```

å¦‚æœå¤šä¸ªçª—å£å‡½æ•°è¦æ±‚åŒä¸€ä¸ªçª—å£è¡Œä¸ºæ—¶ï¼Œè¿™ç§åšæ³•æ˜¯å†—ä½™çš„è€Œä¸”å®¹æ˜“å‡ºé”™çš„ã€‚æ›¿ä»£æ–¹æ¡ˆæ˜¯ï¼Œæ¯ä¸€ä¸ªçª—å£è¡Œä¸ºå¯ä»¥è¢«æ”¾åœ¨ä¸€ä¸ªå‘½åçš„`WINDOW`å­å¥ä¸­ï¼Œç„¶ååœ¨`OVER`ä¸­å¼•ç”¨å®ƒã€‚

```sql
SELECT sum(salary) OVER w, avg(salary) OVER w
  FROM empsalary
  WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);		
```

### ç»§æ‰¿

ç»§æ‰¿æ˜¯é¢å‘å¯¹è±¡æ•°æ®åº“ä¸­çš„æ¦‚å¿µã€‚å®ƒå±•ç¤ºäº†æ•°æ®åº“è®¾è®¡çš„æ–°çš„å¯èƒ½æ€§ã€‚   
å°½ç®¡ç»§æ‰¿å¾ˆæœ‰ç”¨ï¼Œä½†æ˜¯å®ƒè¿˜æœªä¸å”¯ä¸€çº¦æŸæˆ–å¤–é”®é›†æˆï¼Œè¿™ä¹Ÿé™åˆ¶äº†å®ƒçš„å¯ç”¨æ€§ã€‚

```
CREATE TABLE cities (
  name       text,
  population real,
  altitude   int     -- (in ft)
);

CREATE TABLE capitals (
  state      char(2)
) INHERITS (cities);

SELECT name, altitude
    FROM ONLY cities
    WHERE altitude > 500;
```

`ONLY`ç”¨äºæŒ‡ç¤ºæŸ¥è¯¢åªåœ¨`cities`è¡¨ä¸Šè¿›è¡Œè€Œä¸ä¼šæ¶‰åŠåˆ°ç»§æ‰¿å±‚æ¬¡ä¸­ä½äº`cities`ä¹‹ä¸‹çš„å…¶ä»–è¡¨ã€‚å¾ˆå¤šæˆ‘ä»¬å·²ç»è®¨è®ºè¿‡çš„å‘½ä»¤ â€” `SELECT`ã€`UPDATE` å’Œ`DELETE` â€” éƒ½æ”¯æŒè¿™ä¸ª`ONLY`è®°å·ã€‚   



# fedora

Red Hat æ‰€æœ‰çš„è½¯ä»¶äº§å“å…¨éƒ¨æ˜¯å¼€æºï¼ˆOpen Sourced) çš„ã€‚æ³¨æ„æ˜¯â€œæ‰€æœ‰â€ï¼Œæ— ä¸€ä¾‹å¤–ï¼çº¢å¸½æ‰€æœ‰çš„ä¼ä¸šçº§äº§å“ï¼Œä¸€å®šå¯¹åº”ä¸€ä¸ªç¤¾åŒºç‰ˆäº§å“.

å¦‚**RHELçš„ç¤¾åŒºç‰ˆå°±æ˜¯Fedora** 
Redhatæ˜¯æŠŠFedoraä½œä¸ºRHELçš„è¯•éªŒç”°ï¼Œå°±æ˜¯è¯´åœ¨Fedoraä¸Šä¼šå°½é‡ä½¿ç”¨ä¸€äº›æœ€æ–°çš„å†…æ ¸ç‰¹æ€§å’Œç”¨æˆ·å±‚å·¥å…·ï¼Œç­‰è¯•éªŒçš„å·®ä¸å¤šäº†ï¼ŒRHELæŸä¸ªç³»åˆ—çš„Alphaç‰ˆå°±ç›´æ¥Baseåœ¨Fedoraä¹‹ä¸Šã€‚
CentOSåªæ˜¯ç¤¾åŒºå¯¹RHELçš„ç¼–è¯‘ç‰ˆæœ¬ï¼Œè·ŸRHELåº”è¯¥å·®åˆ«ä¸å¤§ã€‚

æˆ‘çœ¼ä¸­çš„å„linuxå‘è¡Œç‰ˆFedora: å°ç™½é¼ ï¼ŒRed Hat ç¶“å¸¸æœƒå¾€ä¸Šå¼·æ¨ä¸€äº›ä¸è€ƒæ…®å…¼å®¹æ€§çš„å¤§è®Šæ›´ã€‚
Arch: é«˜æ•ˆï¼Œè¼•é‡ï¼Œé¢å‘å°ˆæ¥­ç”¨æˆ¶ï¼Œæœ‰ä¸€å®šå±éšªæ€§ã€‚
Ubuntu: é¢å‘åˆç´šç”¨æˆ¶ï¼Œæ¯”è¼ƒå‚»ç“œï¼Œé èƒ½å¹¹çš„å¦¹å¦¹ï¼ˆDebianï¼‰ç…§æ–™ã€‚
Red Hat: ä¼æ¥­ç´šåˆ¥æŠ€è¡“æ”¯æŒã€‚çˆ²äº†ç©©å®šæ€§æ‰€ä»¥ç¶“å¸¸æ¯”è¼ƒè€èˆŠã€‚
CentOS: æœ¬è³ªä¸Šå’Œ Red Hat çš„å…§å®¹æ˜¯ä¸€è‡´çš„ï¼Œä½†æ˜¯æ²’æœ‰æŠ€è¡“æ”¯æŒã€‚å…¼é¡§ Red Hat åŠ£å‹¢ï¼ˆè€èˆŠï¼‰å’Œåˆ¥çš„å¿«é€Ÿç™¼è¡Œç‰ˆçš„åŠ£å‹¢ï¼ˆæ²’æœ‰æŠ€è¡“æ”¯æŒï¼‰ã€‚
Gentoo: å®Œå…¨è‡ªå·±å®šè£½è‡ªå·±ç·¨è­¯ï¼Œå°è‡ªå·±å…¨æ¬Šè² è²¬ï¼Œé¢å‘ã€ŒçœŸæ­£ã€å°ˆæ¥­çš„ç”¨æˆ¶ï¼Œèƒ½åšåˆ°å¾ˆå¤šåˆ¥çš„ç™¼è¡Œç‰ˆåšä¸åˆ°çš„äº‹æƒ…ï¼ŒåŒæ™‚è€—è²»æ™‚é–“ï¼ˆç·¨è­¯ï¼‰å’Œé‡‘éŒ¢ï¼ˆé›»èƒ½ï¼‰ã€‚
openSuSE: ç¾è§€æ¼‚äº®ï¼Œæœ‰å€‹å¼·å¤§çš„ç³»çµ±é…ç½®å·¥å…·ï¼ˆyastï¼‰ç„¡å¾®ä¸è‡³åœ°ç…§é¡§ä½ ï¼Œé¢å‘åˆç´šç”¨æˆ¶ã€‚
slackware: å …æŒè€èˆŠçš„è§€å¿µï¼ˆç”¨æˆ¶æ‡‰è©²è‡ªå·±ç®¡ç†åŒ…ä¾è³´ï¼‰å’Œå¤å…¸ç¾å­¸ã€‚
Debian: èƒ½å¹¹è€Œé è­œï¼Œæ˜¯ Ubuntu çš„å¦¹å¦¹ä½†æ˜¯æ¯” Ubuntu é è­œå¾ˆå¤šã€‚
Mintï¼šå°±æ˜¯Ubuntuå¸¶å€‹é¢å…·



where   record ~ '^[^0-9]+$'; //ä¸åŒ…å«æ•°å­—çš„ğŸ”¢

